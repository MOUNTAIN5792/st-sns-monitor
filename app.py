import streamlit as st
import streamlit.components.v1 as components
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import re
import urllib.parse

st.set_page_config(page_title="ã‚¨ã‚¹ãƒ†ãƒ¼å…¬å¼ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–", layout="centered")

# Xã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆè¡¨ç¤ºç”¨
def render_tweet(tweet_url):
    embed_code = f"""
    <div style="display: flex; justify-content: center;">
        <blockquote class="twitter-tweet" data-conversation="none"><a href="{tweet_url}"></a></blockquote>
    </div>
    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
    """
    components.html(embed_code, height=500, scrolling=True)

st.title("ğŸ¤ @st_product_info æˆæœæŠ½å‡º")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.header("ğŸ” æŠ½å‡ºæ¡ä»¶")
MY_X_ID = "st_product_info"
start_date = st.sidebar.date_input("é–‹å§‹æ—¥", datetime.now() - timedelta(days=365)) # 1å¹´ã«å»¶ã°ã—ã¾ã—ãŸ
end_date = st.sidebar.date_input("çµ‚äº†æ—¥", datetime.now())
min_faves = st.sidebar.slider("æœ€ä½ã„ã„ã­æ•°", 0, 1000, 50) # æœ€åˆã¯50ãã‚‰ã„ã§è©¦ã—ã¾ã—ã‚‡ã†

if st.sidebar.button("å®Ÿç¸¾ã‚’æŠ½å‡ºã™ã‚‹"):
    # æ¤œç´¢ã‚¯ã‚¨ãƒª
    query = f"from:{MY_X_ID} min_faves:{min_faves} since:{start_date} until:{end_date}"
    encoded_query = urllib.parse.quote(query)
    url = f"https://search.yahoo.co.jp/realtime/search?p={encoded_query}"
    
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}
    
    with st.spinner('æ¢ç´¢ä¸­...'):
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        
        # 1. ã¾ãšã¯ã€ŒåŸ‹ã‚è¾¼ã¿ã€ç”¨ã®URLã‚’æ¢ã™
        links = soup.find_all("a", href=re.compile(r'status/\d+'))
        tweet_urls = list(dict.fromkeys([l['href'].split('?')[0] for l in links if "twitter.com" in l['href'] or "x.com" in l['href']]))

        # 2. URLãŒè¦‹ã¤ã‹ã‚Œã°ã€ŒåŸ‹ã‚è¾¼ã¿ã€ã€è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ã€Œãƒ†ã‚­ã‚¹ãƒˆã€ã‚’è¡¨ç¤º
        if tweet_urls:
            st.success(f"{len(tweet_urls[:10])}ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            for t_url in tweet_urls[:10]:
                render_tweet(t_url)
        else:
            # URLãŒæ‹¾ãˆãªã„å ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã§ã‚‚å‡ºã™
            posts = soup.find_all(["p", "span"], class_=lambda x: x and "Tweet_body" in x)
            if posts:
                st.info("URLãŒç›´æ¥å–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§è¡¨ç¤ºã—ã¾ã™ã€‚")
                for p in posts[:10]:
                    st.markdown(f"""
                    <div style="border:1px solid #ddd; padding:15px; border-radius:10px; margin-bottom:10px; background:white;">
                        {p.get_text()}
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.warning("Yahoo!ã®æ¤œç´¢çµæœã«æŠ•ç¨¿ãŒè¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’ã•ã‚‰ã«ç·©ã‚ã‚‹ã‹ã€å°‘ã—æ™‚é–“ã‚’ç½®ã„ã¦è©¦ã—ã¦ãã ã•ã„ã€‚")
