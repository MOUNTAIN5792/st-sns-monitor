import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time

# ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«
st.set_page_config(page_title="SNSãƒˆãƒ¬ãƒ³ãƒ‰ç›£è¦–", layout="wide")
st.title("ğŸ”¥ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ SNSãƒˆãƒ¬ãƒ³ãƒ‰ç›£è¦–")

# --- è¨­å®šç”¨ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.header("æ¤œç´¢è¨­å®š")
search_keyword = st.sidebar.text_input("æ°—ã«ãªã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", "ãƒˆãƒ¬ãƒ³ãƒ‰")
update_interval = st.sidebar.slider("è‡ªå‹•æ›´æ–°ã®é–“éš” (ç§’)", 10, 300, 60)

# --- ãƒ‡ãƒ¼ã‚¿ã‚’å–ã£ã¦ãã‚‹é–¢æ•° ---
def get_trends(keyword):
    # Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ã‹ã‚‰æƒ…å ±ã‚’èª­ã¿å–ã‚‹
    url = f"https://search.yahoo.co.jp/realtime/search?p={keyword}"
    headers = {"User-Agent": "Mozilla/5.0"} # ã‚µã‚¤ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã®ã€Œååˆºã€ã®ã‚ˆã†ãªã‚‚ã®
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    
    items = []
    # æŠ•ç¨¿ã®ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã‚’æŠœãå‡ºã™
    posts = soup.select(".Tweet_body__idmUf")
    
    for post in posts[:10]:
        items.append({"æœ€æ–°ã®æŠ•ç¨¿å†…å®¹": post.get_text()})
    return pd.DataFrame(items)

# --- ç”»é¢ã®è¡¨ç¤ºã‚’æ›´æ–°ã—ç¶šã‘ã‚‹ãƒ«ãƒ¼ãƒ— ---
placeholder = st.empty()

while True:
    with placeholder.container():
        st.subheader(f"ã€Œ{search_keyword}ã€ã«é–¢ã™ã‚‹ä»Šã®è©±é¡Œ")
        df = get_trends(search_keyword)
        
        if not df.empty:
            st.table(df) # è¡¨å½¢å¼ã§è¡¨ç¤º
            st.info(f"æœ€çµ‚æ›´æ–°æ™‚åˆ»: {time.strftime('%H:%M:%S')}")
        else:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®è¨€è‘‰ã§è©¦ã—ã¦ãã ã•ã„ã€‚")
            
    time.sleep(update_interval)